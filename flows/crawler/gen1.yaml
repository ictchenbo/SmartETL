name: 通用爬虫流程
arguments: 2
consts:
  headers:
    User-Agent: "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
  proxy:
    http: http://localhost:8001
    https: http://localhost:8001

nodes:
  loader1: String(arg1)
  loader2: QueueLoader
  distinct: Distinct
  as_dict: ToDict
  download: Map('util.http.text', key='d', target_key='content', most_times=1, ignore_error=True, content_type='text/html', timeout=30, headers=headers, proxies=proxy, verify=False)
  filter: FieldsNonEmpty('content')
  extract: Map('gestata.crawler.extract', base_url_key='d')
  writer: WriteJson(f'data/spider/pages-{arg2}.json', append=True, buffer_size=1)
  flat: Flat(key='links')
  append: WriteQueue(loader2.queue)

loader: MultiLoader(loader1, loader2)
processor: Chain(Print(), distinct, as_dict, download, filter, extract, writer, Count(ticks=1), flat, append)
