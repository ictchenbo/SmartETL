from: local/db_envs.yaml

name: paper file scan
description: 扫描文件夹读取论文文件，根据HTML/PDF写入不同的Kafka队列

consts:
  kafka_host: 10.208.57.21:9092

nodes:
#  minio: util.database.minio.MinIO(**minio, bucket='paper-2506', auto_create=True)
  es: util.database.elasticsearch.ES(**es1, index='paper-2506')
  kafka1: util.database.kafka.Kafka(host=kafka_host, topic='arxiv_html_0911', auto_create=True)
  kafka2: util.database.kafka.Kafka(host=kafka_host, topic='arxiv_pdf_1117', auto_create=True)

# 论文ID：`arxiv:<arxiv-id>`
  add_id: Map('gestata.arxiv.make_id', key='filename', target_key='_id')

# 如果主结构json文件存在，则不处理
  filter_exist: DistinctByDatabase(es, key='_id')

# 保存html|pdf文件到MinIO
#  save_html: Map('gestata.dbops.upsert', minio, key_key='path_html', value_key='data')
#  save_pdf: Map('gestata.dbops.upsert', minio, key_key='path_pdf', value_key='data')

  kafka_html: Map('gestata.dbops.upsert', kafka1)

  split_pdf: Map('gestata.pdf.split', key=('_id', 'filepath'), target_key=None, output_dir=arg2, pages_per_file=2)
  kafka_pdf: Map('gestata.dbops.upsert', kafka2)
  chain_pdf: Chain(split_pdf, kafka_pdf)

  is_html: "=lambda r: r['filename'].endswith('.html')"
  ifelse: IfElse(kafka_html, chain_pdf, matcher=is_html)

# 扫描文件夹 获取全部html/pdf文件 输出文件名
loader: Directory(arg1, '.html', '.pdf', recursive=True, filename_only=True)

processor: Chain(add_id, filter_exist, ifelse)
