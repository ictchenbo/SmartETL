from: local/db_envs.yaml

name: paper process flow
description: 扫描文件夹读取论文，生成哈希id，如果是HTML则直接处理入库，如果是PDF，则写入Kafka任务
#limit: 1

consts:
  type_mapping:
    all: .raw
  ex_meta:
    source:
      name: arXiv
  kafka_host: 10.60.1.148:9092
  paths:
    - /data/datax/papers/arxiv/2505
    - /data/datax/papers/arxiv/2506
    - /data/datax/papers/arxiv/2507
    - /data/datax/papers/arxiv/2508

nodes:
  minio: util.database.minio.MinIO(**minio, bucket='paper-2506', auto_create=True)
  es: util.database.elasticsearch.ES(**es1, index='paper-2506')
  kafka: util.database.kafka.Kafka(host=kafka_host, topic='arxiv_html')

# 论文ID：`arxiv:<arxiv-id>`
  add_id: Map('gestata.arxiv.make_id', key='filename', target_key='_id')
  add_meta: Map('gestata.paper.add_meta')

# 如果主结构json文件存在，则不处理
  filter_exist: DistinctByDatabase(es, key='_id')

# 读取文件内容
  read_file: Map('util.files.content', key='filepath', target_key='data')

# HTML解析 TODO 图片下载&统一格式
  save_html: Map('gestata.dbops.upsert', minio, key_key='path_html', value_key='data')
#  add_url: ConcatFields('url_html', 'filename', prefix='http://arxiv.org/html/')
  extract_html: Map('gestata.arxiv.extract', target_key='paper', content_key='data')

#PDF解析 TODO 可以从mineru下载解析的论文图片
  save_pdf: Map('gestata.dbops.upsert', minio, key_key='path_pdf', value_key='data')
  write_kafka: Map('gestata.dbops.upsert', kafka)
  pdf_chain: Chain(Print('sid', 'path_pdf', 'path_md'), save_pdf, RemoveFields('data'), Buffer(buffer_size=100), write_kafka)

# 简化paper结构&保存完整JSON结构
  fill_meta: Map('gestata.paper.fill_paper', data=ex_meta)
  save_paper: Map('gestata.dbops.upsert', minio, key_key='store_path', value_key='paper')

# 建立ES全文索引
#  write_es: Chain(Map('gestata.dbops.upsert', es, key='paper'), Count(label='es'))
  write_es: Chain(SelectVal('paper'), Count(label='es'), Buffer(buffer_size=100), Map('gestata.dbops.upsert', es))

  html_chain: Chain(Print('sid', 'path_html'), save_html, extract_html, FieldsNonEmpty('paper'), fill_meta, save_paper, write_es)
  is_html: "=lambda r: r['filename'].endswith('.html')"
  ifelse: IfElse(html_chain, pdf_chain, matcher=is_html)

# 扫描文件夹 获取全部html/pdf文件 输出文件名
loader: Directory(paths, '.html', '.pdf', filename_only=True)
# 暂不处理图片 仅存储在MinIO和ES
processor: Chain(add_id, add_meta, filter_exist, read_file, ifelse)
