from: local/db_envs.yaml

name: load and extract news from web page
description: 接收采集平台通过Kafka推送的网页数据，进行标题、时间、作者、正文等抽取

#loader: database.kafka.WebConsumer(**kafka, topics=['gdelt'])
loader: database.kafka.TimedConsumer(**kafka, topics=['gdelt'], max_wait_times=15)
#loader: JsonLine('data/news2.jsonl')

nodes:
  count: Count(ticks=10)
  print: Print('id', 'url')
  select: Select('id', 'url', 'html', 'event_time_date', 'mention_time_date')
  backup: WriteJsonScroll('data/gdelt/news')
  extract: nlp.news.Constor('http://10.60.1.145:7100/constor/process', key='html')
#  extract: nlp.news.Extract(key='html', target_key='content')
  flat: FlatProperty('html', inherit_props=True)
  valid_time: "=lambda r: r['publish_time'] < r['event_time_date'] + 86400000 if r.get('publish_time') else False"
  backup_bad: WriteJsonIf(valid_time, 'data/gdelt/bad', scroll=100)
  chain: Chain(select, extract, flat, backup_bad)

#processor: Chain(chain, Select('id', 'title', 'origin_publish_time', 'url'), print)
processor: Chain(chain, Print(), count)
