from: local/llm_keys.yaml

name: 大模型调用处理
description: 调用Kimi（月之暗面）/Siliconflow平台的大模型处理输入的问题 支持配置数据字段field，服务Key api_key，模型model，代理proxy，温度temp，topk，topp参数
arguments: 0
consts:
  proxy: 'http://localhost:8001'
  model: THUDM/glm-4-9b-chat

loader: Text('test_data/llm_inputs.txt')

nodes:
  llm1: model.Moonshot(**kimi)
  llm2: model.Siliconflow(**siliconflow, model=model, proxy=proxy)
  print: Print

processor: Chain(llm2, print)
