from:
  - local/db_envs.yaml
  - flows/arxiv/arxiv_p1_meta.yaml
name: arxiv论文下载解析
description: 通过命令行行输入搜索关键词，检索arXiv论文，获取其HTML网页，并解析，内容向量化写入向量化库
consts:
  qdrant:
    collection: chunk_arxiv
  bge_large_zh: http://10.208.63.29:8001/embed
  headers:
    User-Agent: chenbo01@ict.ac.cn


nodes:
  download: Map('util.http.content', key='url_pdf', target_key='content', most_times=3, ignore_error=True, headers=headers)
  filter: FieldsNonEmpty('content')
  save_file: WriteFiles('data/arxiv/pdf', name_key='_id', suffix='.pdf')
  pdf_extract: Map('gestata.arxiv.extract', target_key='paper')
#  chunk: Map('util.split.simple', key='md_content',target_key='chunks')
#  flat_chunk: Flat(key='chunks', inherit_props=True)
#  vector: model.embed.Local(api_base=bge_large_zh, key='chunks', target_key='vector')
#  write_qd: database.qdrant.Qdrant(**qdrant, buffer_size=1)

#  chain1: Chain(search, Flat(), download, save_file, pdf_extract, chunk, flat_chunk, vector, write_qd, Count(ticks=1))

  writer: WriteJson('test_data/arxiv_full.json', buffer_size=1)
#  chain2: Chain(search, Flat(), download, filter, save_file, pdf_extract, writer)
  chain2: Chain(SkipN(25), search, download, filter, save_file, Wait(5))
#, pdf_extract, writer, Wait(3))

processor: chain2
